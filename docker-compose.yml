version: "3.7"
services:
  mimic:
    image: arkhn/mimic:latest
    container_name: mimic
    env_file: .env
    restart: always
    environment:
      POSTGRES_USER: mimicuser
      POSTGRES_PASSWORD: mimicuser
      POSTGRES_DB: mimic
      POSTGRES_HOST: mimic
      POSTGRES_PORT: 5432
    volumes:
      - mimic-db:/var/lib/postgresql/data
    ports:
      - 5431:5432
    networks:
      - river-network

  mongo:
    image: mongo
    restart: always
    environment:
      MONGO_INITDB_DATABASE: fhirstore
    ports:
      - 27017:27017
    volumes:
      - fhirstore-db:/data/db
    networks:
      - river-network

  # sftp:
  #   image: atmoz/sftp
  #   container_name: sftp
  #   volumes:
  #     - ~/Documents/Arkhn/river-river/test/sftp/host/upload/:/home/arkhn/upload/
  #   ports:
  #     - "2222:22"
  #   command: arkhn:arkhnpwd:1001

  zookeeper:
    image: "zookeeper:3.4.10"
    container_name: zookeeper
    restart: always
    ports:
      - "2181:2181"
    expose:
      - "2181"
    networks:
      - river-network

  kafka:
    image: "wurstmeister/kafka:0.10.2.1"
    restart: always
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    expose:
      - "9092"
    environment:
      - KAFKA_ADVERTISED_HOST_NAME=kafka
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_DELETE_TOPIC_ENABLE=true
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - river-network

  #  kafka_connect:
  #    image: confluentinc/cp-kafka-connect:latest
  #    restart: always
  #    container_name: kafka_connect
  #    ports:
  #      - "8083:8083"
  #    depends_on:
  #      - kafka
  #    volumes:
  #      - ./kafka_connect_connectors/plugins/confluentinc-kafka-connect-sftp-1.0.4/:/usr/share/java/kafka-connect-sftp/
  #    environment:
  #      CONNECT_CLASS_PATH: "/usr/share/java/kafka-connect-jdbc/,/usr/share/java/kafka-connect-sftp/"
  #      CONNECT_PLUGIN_PATH: /usr/share/java/
  #      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
  #      CONNECT_GROUP_ID: source-kafka-connect
  #      CONNECT_CONFIG_STORAGE_TOPIC: default.config
  #      CONNECT_STATUS_STORAGE_TOPIC: default.status
  #      CONNECT_OFFSET_STORAGE_TOPIC: default.offset
  #      CONNECT_STATUS_STORAGE_PARTITIONS: 1
  #      CONNECT_OFFSET_STORAGE_PARTITIONS: 1
  #      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
  #      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
  #      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
  #      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
  #      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
  #      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
  #      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
  #      CONNECT_REST_PORT: 8083
  #      CONNECT_REST_ADVERTISED_HOST_NAME: docker
  #      CONNECT_SCHEMAS_ENABLE: "false"
  #      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
  #      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
  #      CONNECT_ZOOKEEPER_CONNECT: zookeeper:2181

  api:
    build:
      context: ./apigo
    container_name: api
    image: arkhn/river-api-go:latest
    restart: always
    depends_on:
      - kafka
      - fluentd
    environment:
      PORT: 3000
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      EXTRACTOR_URL: http://extractor:3001
      TRANSFORMER_URL: http://transformer:3002
    ports:
      - "3000:3000"
    networks:
      - river-network

  extractor:
    build:
      dockerfile: extractor/Dockerfile
      context: ./
    container_name: extractor
    image: arkhn/river-extractor:latest
    restart: always
    depends_on:
      - kafka
      - fluentd
    env_file:
      - .env
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      SERVICE_NAME: extractor
    ports:
      - 3001:3001
    networks:
      - river-network

  transformer:
    build:
      dockerfile: transformer/Dockerfile
      context: ./
    container_name: transformer
    image: arkhn/river-transformer:latest
    restart: always
    depends_on:
      - kafka
      - fluentd
    env_file:
      - .env
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      FHIRSTORE_HOST: mongo
      FHIRSTORE_PORT: 27017
      FHIRSTORE_DATABASE: fhirstore
      FHIRSTORE_USER: null
      FHIRSTORE_PASSWORD: null
      SERVICE_NAME: transformer
    ports:
      - 3002:3002
    networks:
      - river-network

  loader:
    build:
      dockerfile: loader/Dockerfile
      context: ./
    container_name: loader
    image: arkhn/river-loader:latest
    restart: always
    depends_on:
      - kafka
      - mongo
      - fluentd
    env_file:
      - .env
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      FHIRSTORE_HOST: mongo
      FHIRSTORE_PORT: 27017
      FHIRSTORE_DATABASE: fhirstore
      FHIRSTORE_USER: null
      FHIRSTORE_PASSWORD: null
      METRICS_PORT: 3003
      SERVICE_NAME: loader
    ports:
      - 3003:3003
    networks:
      - river-network

  # Uncomment if you want monitoring
  # prometheus:
  #   container_name: prometheus
  #   image: prom/prometheus:latest
  #   volumes:
  #     - ./prometheus.yaml:/etc/prometheus/prometheus.yml
  #   ports:
  #     - "9090:9090"
  #   networks:
  #     - river-network
  # grafana:
  #   container_name: grafana
  #   image: grafana/grafana:latest
  #   ports:
  #     - 3010:3000
  #   volumes:
  #     - ./grafana/config.ini:/etc/grafana/config.ini
  #     - ./grafana/provisioning:/etc/grafana/provisioning
  #     - ./grafana/dashboards:/var/lib/grafana/dashboards
  #   networks:
  #     - river-network

  fluentd:
    image: arkhn/fluentd:latest
    container_name: fluentd
    volumes:
      - ./fluentd/conf:/fluentd/etc
    ports:
      - 127.0.0.1:24224:24224
      - "24224:24224/udp"
    networks:
      - river-network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: elasticsearch
    volumes:
      - ./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    expose:
      - 9200
    ports:
      - "9200:9200"
    networks:
      - river-network

  kibana:
    image: docker.elastic.co/kibana/kibana:7.7.0
    container_name: kibana
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    networks:
      - river-network

volumes:
  mimic-db:
    name: mimic-db
  fhirstore-db:

networks:
  river-network:
    name: river-network
