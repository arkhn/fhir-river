version: "3.7"

services:
  extractor:
    image: river
    build: .
    command: extractor
    depends_on:
      - kafka
    restart: on-failure
    environment:
      - ENV=dev
      - LOG_LEVEL=DEBUG
      - REDIS_HOST=river-redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - SECRET_KEY=USE_IN_DEVELOPMENT_ONLY
      - POSTGRES_DB=river
      - POSTGRES_USER=river
      - POSTGRES_PASSWORD=river
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432

  transformer:
    image: river
    build: .
    command: transformer
    depends_on:
      - kafka
    restart: on-failure
    environment:
      - ENV=dev
      - LOG_LEVEL=DEBUG
      - REDIS_HOST=river-redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - SECRET_KEY=USE_IN_DEVELOPMENT_ONLY
      - POSTGRES_DB=river
      - POSTGRES_USER=river
      - POSTGRES_PASSWORD=river
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432

  topicleaner:
    image: river
    build: .
    command: topicleaner
    depends_on:
      - kafka
      - river-redis
    restart: on-failure
    environment:
      - ENV=prod
      - LOG_LEVEL=INFO
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - REDIS_HOST=river-redis
      - REDIS_PORT=6379
      - REDIS_DB=0

  db:
    image: postgres:12
    restart: on-failure
    ports:
      - 5432:5432
    environment:
      - POSTGRES_DB=river
      - POSTGRES_USER=river
      - POSTGRES_PASSWORD=river
    volumes:
      - db-data:/var/lib/postgresql/data

  mimic:
    image: arkhn/mimic:latest
    ports:
      - 15432:5432
    environment:
      POSTGRES_USER: test
      POSTGRES_PASSWORD: test
      POSTGRES_DB: test
    volumes:
      - mimic-data:/var/lib/postgresql/data

  river-api:
    image: river
    build: .
    restart: on-failure
    ports:
      - "8000:8000"
    environment:
      - ENV=dev
      - ADMIN_ENABLED=True
      - ALLOWED_HOSTS=*
      - CORS_ALLOW_ALL_ORIGINS=True
      - CORS_ALLOW_CREDENTIALS=True
      - RF_DEFAULT_RENDERER_CLASSES=rest_framework.renderers.JSONRenderer,rest_framework.renderers.BrowsableAPIRenderer
      - RF_DEFAULT_PERMISSION_CLASSES=rest_framework.permissions.AllowAny
      - LOG_LEVEL=DEBUG
      - DEBUG=True
      - SECRET_KEY=whatever
      - FHIR_API_URL=${FHIR_API_URL}
      - FHIR_API_AUTH_TOKEN=${FHIR_API_AUTH_TOKEN}
      - REDIS_HOST=river-redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - SECRET_KEY=USE_IN_DEVELOPMENT_ONLY
      - POSTGRES_DB=river
      - POSTGRES_USER=river
      - POSTGRES_PASSWORD=river
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432
      - DJANGO_SUPERUSER_USERNAME=admin
      - DJANGO_SUPERUSER_EMAIL=admin@admin.admin
      - DJANGO_SUPERUSER_PASSWORD=admin
      - OIDC_RP_CLIENT_ID=${OIDC_RP_CLIENT_ID}
      - OIDC_RP_CLIENT_SECRET=${OIDC_RP_CLIENT_SECRET}
      - OIDC_RP_EXTRA_SCOPES=${OIDC_RP_EXTRA_SCOPES}
      - OIDC_RP_SIGN_ALGO=${OIDC_RP_SIGN_ALGO}
      - OIDC_TOKEN_USE_BASIC_AUTH=${OIDC_TOKEN_USE_BASIC_AUTH}
      - LOGIN_REDIRECT_URL=${LOGIN_REDIRECT_URL}
      - LOGIN_REDIRECT_URL_FAILURE=${LOGIN_REDIRECT_URL_FAILURE}
      - LOGOUT_REDIRECT_URL=${LOGOUT_REDIRECT_URL}
      - DISABLE_AUTH=${DISABLE_AUTH}
      # LPT: Always use 127.0.0.1 (not localhost) in public URLs redirecting to the provider
      # This is to prevent cookies in the browser from being shared and overridden by
      # different services running on the host.
      - OIDC_OP_AUTHORIZATION_ENDPOINT=${OIDC_OP_AUTHORIZATION_ENDPOINT}
      - OIDC_OP_TOKEN_ENDPOINT=${OIDC_OP_TOKEN_ENDPOINT}
      - OIDC_OP_USER_ENDPOINT=${OIDC_OP_USER_ENDPOINT}
      - OIDC_OP_JWKS_ENDPOINT=${OIDC_OP_JWKS_ENDPOINT}

  zookeeper:
    image: zookeeper:3.4.10
    restart: on-failure

  kafka:
    image: wurstmeister/kafka:2.13-2.6.0
    restart: on-failure
    # This port mapping is required by the containerized kafka
    ports:
      - "19092:19092"
    depends_on:
      - zookeeper
    environment:
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONNECTIONS_FROM_HOST://:19092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,CONNECTIONS_FROM_HOST://localhost:19092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONNECTIONS_FROM_HOST:PLAINTEXT
      - KAFKA_DELETE_TOPIC_ENABLE=true
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      # The following option can be used in local, but should not be used in production.
      # It constrains the initial/maximum virtual memory allocated for the JVM.
      # - KAFKA_HEAP_OPTS=-Xmx256M -Xms128M
      - KAFKA_JMX_OPTS=-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka -Dcom.sun.management.jmxremote.rmi.port=9993 -Dcom.sun.management.jmxremote.port=9993
      - JMX_PORT=9993
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  river-redis:
    image: redis:6.0.7
    ports:
      - "6379:6379"
    restart: on-failure
    command: --loglevel verbose

volumes:
  db-data:
  mimic-data:

networks:
  default:
    external:
      name: arkhn_network
